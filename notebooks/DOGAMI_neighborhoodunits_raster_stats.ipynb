{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook for analyzing DOGAMI data, see Scott Tse's emergence-response notebook at\n",
    "# https://github.com/hackoregon/emergency-response/blob/analytics/notebooks/census_eda_geo.ipynb\n",
    "# NOTE: Don't need all of these!\n",
    "# Import modules included in \"kitchen-sink\"\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "import sys\n",
    "# Import modules NOT included in \"kitchen-sink\", not sure about osgeo...\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import geoplot as gplt\n",
    "from osgeo import osr, ogr\n",
    "from pyproj import Geod  # not sure if this is in kitchen-sink or not...\n",
    "#import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.D. Pearce, 04/16/18\n",
    "\n",
    "Notebook for computing statistics on raster pixel values contained within a geometry (shape) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ALL parameters in dictionary (convert to json config file!)\n",
    "params = {\n",
    "    'raster': {\n",
    "        'root': './CSZ_M9p0_',\n",
    "        'names': ['pgv_site', 'PGD_landslide_dry', 'PGD_landslide_wet', 'PGD_liquefaction_wet'],\n",
    "        'ext': '.tif'\n",
    "    },\n",
    "    'geometry': {\n",
    "        'from_postgis': {\n",
    "            'query': {\n",
    "                'table_name': 'neighborhood_units',\n",
    "                'select_cols': 'nuid',\n",
    "                'geometry_col': 'wkb_geometry',\n",
    "                'epsg_code': 4326\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'zonal_stats': {\n",
    "        'layer': 1,\n",
    "        'stats': ['count', 'min', 'max', 'mean', 'std']\n",
    "        \n",
    "    },\n",
    "    'stats_classification': {\n",
    "        'stats_to_class': ['min', 'max', 'mean'],\n",
    "        'pgv_site': {\n",
    "            'levels': [-9999, 0.1, 1.1, 3.4, 8.1, 16, 31, 60, 116, 9999],\n",
    "            'level_labels': ['I', 'II-III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X'],\n",
    "            'class_name': 'Modified Mercalli Intensity',\n",
    "            'class_tag': 'MMI'\n",
    "        },\n",
    "        'PGD_landslide_dry': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Landslide Intensity (Dry)',\n",
    "          'class_tag': 'DI'\n",
    "        },\n",
    "        'PGD_landslide_wet': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Landslide Intensity (Wet)',\n",
    "          'class_tag': 'DI'\n",
    "        },\n",
    "        'PGD_liquefaction_wet': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Liquefaction Intensity (Wet)',\n",
    "          'class_tag': 'DI'\n",
    "        }\n",
    "    },\n",
    "    'write_csv': {\n",
    "        'name': \"./DOGAMI_neighborhoodunits_raster_stats.csv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for obtaining geopandas dataframe containing geometry column from either\n",
    "# 1) a local file (e.g. .dba file) or 2) interacting with PostGres database\n",
    "def pgconnect():\n",
    "    \"\"\"Establish connection to PostGres database using the parameters specified in .env file.\n",
    "    First, walk root diretory to find and load .env file w/ PostGres variables defining database, \n",
    "    user, host, password, and port variables.\n",
    "    Then, return connection to database from psycopg2.connect\n",
    "    \"\"\"\n",
    "    try:\n",
    "        load_dotenv(find_dotenv())\n",
    "        conn = psycopg2.connect(database=os.environ.get(\"PG_DATABASE\"), user=os.environ.get(\"PG_USER\"), \n",
    "                            password = os.environ.get(\"PG_PASSWORD\"), \n",
    "                            host=os.environ.get(\"PG_HOST\"), port=os.environ.get(\"PG_PORT\"))\n",
    "        print(\"Opened database successfully\\n\")\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"I am unable to connect to the database\\n\")\n",
    "        print(e)\n",
    "        print(e.pgcode)\n",
    "        print(e.pgerror)\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "def get_query_string(table_name, select_cols, geometry_col, epsg_code):\n",
    "    \"\"\"Build query string from parameter inputs defining table name, all the columns\n",
    "    to select, select_cols, the column that defines the geometry, geometry_col, and\n",
    "    the epsg code that defines the ellipsoid.\n",
    "    \"\"\"\n",
    "    query_string = 'SELECT ' + select_cols + ', ' + \\\n",
    "            'ST_TRANSFORM({}, {}) AS geometry'.format(geometry_col, epsg_code)\n",
    "    return query_string + ' FROM {}'.format(table_name)\n",
    "    \n",
    "    \n",
    "def get_geometry_from_postgis(postgis_params):\n",
    "    '''\n",
    "    This function takes a dictionary containing parameters for building a SQL query,\n",
    "    as defined in get_query_string, then connects to a postgis db, selects the \n",
    "    data specified in the query, and finally returns a geodataframe with a single\n",
    "    column named geometry that contains shape data.\n",
    "    '''\n",
    "    query_string = get_query_string(**postgis_params['query'])\n",
    "    conn = pgconnect()\n",
    "    #cur = conn.cursor()\n",
    "    print(\"SQL QUERY = \"+query_string+'\\r\\n')\n",
    "    try:\n",
    "        geo_df = gpd.GeoDataFrame.from_postgis(\n",
    "            query_string, \n",
    "            conn, \n",
    "            geom_col='geometry', \n",
    "            crs={'init': u'epsg:{}'.format(postgis_params['query']['epsg_code'])}, \n",
    "            coerce_float=False\n",
    "        )\n",
    "        return geo_df\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        \n",
    "def get_geometry_from_file(name, geom_col='geometry'):\n",
    "    \"\"\"Import geometry from a file using geopandas.read_file\n",
    "    Returns only the geometry column!\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(name)\n",
    "    #print(type(gdf))\n",
    "    return gdf\n",
    "\n",
    "def calc_square_lonlat(lon_lat, xy_offset):\n",
    "    \"\"\"Calculate the longitude and latitude corresponding to the upper-right and lower-left\n",
    "    corners of a square box centered on lat_lon, with a width of 2*xy_offset. \n",
    "    xy_offset MUST be in meters. Uses WGS84 (epsg=4326) ellipsoid.\n",
    "    \"\"\"\n",
    "    az = [45, 225]\n",
    "    lon = 2*[lon_lat[0]]\n",
    "    lat = 2*[lon_lat[1]]\n",
    "    mag = 2*[np.sqrt(2)*xy_offset]\n",
    "    g = Geod(ellps='WGS84')\n",
    "    rl_lon, tb_lat, _ = g.fwd(lon, lat, az, mag)\n",
    "    return (rl_lon, tb_lat)\n",
    "\n",
    "def calc_square_polygon(lon_lat, xy_offset):\n",
    "    \"\"\"Calculate polygon defining square box centered on lon, lat (decimal degrees)\n",
    "    with a width of 2*xy_offset (meters).\n",
    "    \"\"\"\n",
    "    rl_lon, tb_lat = calc_square_lonlat(lon_lat, xy_offset)\n",
    "    poly = [Polygon((\n",
    "            (rl_lon[0], tb_lat[0]),\n",
    "            (rl_lon[0], tb_lat[1]),\n",
    "            (rl_lon[1], tb_lat[1]),\n",
    "            (rl_lon[1], tb_lat[0])\n",
    "    ))]\n",
    "    return poly\n",
    "\n",
    "def get_geometry_from_point(lon_lat, xy_offset, xy_units=\"m\"):\n",
    "    \"\"\"Returns a geodataframe containing a single geometry column that\n",
    "    defines a square box centered on a point, specified as a lat, lon pair,\n",
    "    The input parameter xy_offset defines the box half-width \n",
    "    1) Calculate the top-right corner and bottom-left corner of square box\n",
    "    centered on lon_lat, using the WGS84 ellipsoid.\n",
    "    2) Use the lon, lat of each corner to build a rectangular \n",
    "    polygon using shapely Polygon.\n",
    "    3) Convert polygon to pandas geodataframe, set coordinate reference to \n",
    "    epsg 4326 (equivalent to WGS84).\n",
    "    \"\"\"\n",
    "    if xy_units == \"m\":\n",
    "        poly = get_square_polygon(lon_lat, xy_offset)\n",
    "        # Build geodataframe with one row, column\n",
    "        gdf = gpd.GeoDataFrame(poly, columns=['geometry'], geometry='geometry')\n",
    "        gdf.crs = {'init' :'epsg:4326'}\n",
    "        return gdf\n",
    "    else:\n",
    "        print(\"Error: input xy_offset MUST be in meters!!!\")\n",
    "\n",
    "def get_geodf_geometry(**kwargs):\n",
    "    \"\"\"Import geometry either from point and size, a file, or from postgis db\n",
    "    \"\"\"\n",
    "    if 'from_point' in kwargs:\n",
    "        return get_geometry_from_point(**kwargs['from_point'])\n",
    "    elif 'from_file' in kwargs:\n",
    "        return get_geometry_from_file(**kwargs['from_file'])\n",
    "    elif 'from_postgis' in kwargs:\n",
    "        return get_geometry_from_postgis(kwargs['from_postgis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for manipulating geoshapes and raster files\n",
    "def get_gdfcrs_epsg(gdf):\n",
    "    \"\"\"Return integer EPSG code corresponding to Coordinate Reference\n",
    "    used in input geodataframe, gdf. Attribute gdf.crs must contain\n",
    "    a dict with key = 'init' that contains a string starting with 'epsg',\n",
    "    followed by a colon, followed by an integer as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dfepsg = gdf.crs['init'].split(':')\n",
    "        if dfepsg[0] == 'epsg':\n",
    "            return int(dfepsg[1])\n",
    "    except:\n",
    "        print('Error: geodataframe crs = {}, unrecognized EPSG integer'.format(gdf.crs['init']))\n",
    "\n",
    "def get_raster_info_srs(raster_file, print_info=True):\n",
    "    \"\"\"Print information about raster file, and return its\n",
    "    spatial reference system using gdal.\n",
    "    \"\"\"\n",
    "    if print_info:\n",
    "        try:\n",
    "            print(gdal.Info(raster_file))\n",
    "        except:\n",
    "            print(\"Error reading info from raster file = {}\".format(raster_file))\n",
    "    try:\n",
    "        raster = gdal.Open(raster_file)\n",
    "    except:\n",
    "        print(\"Error opening raster file = {}\".format(raster_file))\n",
    "    else:\n",
    "        raster_srs = osr.SpatialReference()\n",
    "        raster_srs.ImportFromWkt(raster.GetProjection())\n",
    "        return raster_srs\n",
    "\n",
    "def transform_polygons_from_srsinp_to_srsout(geom_col, srs_out):\n",
    "    \"\"\"Transform list of georeferenced polygon geometries from geopandas\n",
    "    dataframe geometry column, geom_col, to the desired output Spatial Reference, srs_out.\n",
    "    The input geometry column, geom_col, MUST have a valid epsg code defining its Spatial \n",
    "    Reference (SRS).\"\"\"\n",
    "    # Define input spatial reference using epsg code from gdf\n",
    "    srs_inp = ogr.osr.SpatialReference()\n",
    "    srs_inp.ImportFromEPSG(get_gdfcrs_epsg(geom_col))\n",
    "    poly_out = []\n",
    "    # Define list of polygons in transformed spatial reference\n",
    "    for g in geom_col:\n",
    "        # If MultiPolygon, then assume it contains only one Polygon\n",
    "        if g.type == 'MultiPolygon':\n",
    "            poly = ogr.CreateGeometryFromWkt(g.geoms[0].wkt)\n",
    "        elif g.type == 'Polygon':\n",
    "            # Need to test this\n",
    "            poly = ogr.CreateGeometryFromWkt(g.wkt)\n",
    "        else:\n",
    "            print(\"Error: geometry = {}, MUST be Polygon or MultiPolygon\".format(g.type))\n",
    "        poly.AssignSpatialReference(srs_inp)\n",
    "        # Transform point co-ordinates so that they are in same projection as raster \n",
    "        poly.Transform(osr.CoordinateTransformation(srs_inp, srs_out))\n",
    "        poly_out.append(poly.ExportToWkt())\n",
    "    return poly_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for computing raster statistics\n",
    "def get_raster_stats_df(geom_ras, df_index, raster_file, raster_name, **kwargs):\n",
    "    \"\"\"Compute raster statistics for input geometry and raster file.\n",
    "    Return results in dataframe\n",
    "    \"\"\"\n",
    "    geomstats = zonal_stats(geom_ras, raster_file, **kwargs)\n",
    "    df_gs = pd.DataFrame(geomstats, index=df_index)\n",
    "    df_gs.rename(columns={co: raster_name+'_'+co for co in df_gs.columns}, inplace=True)\n",
    "    return df_gs\n",
    "\n",
    "# Functions for classifying raster statistics\n",
    "def get_stats_classification(gdf, **kwargs):\n",
    "    \"\"\"Classify raster statistics using specified parameters in kwargs\"\"\"\n",
    "    raster_names = [rn for rn in kwargs.keys() if rn != \"stats_to_class\"]\n",
    "    for rn in raster_names:\n",
    "        stats_to_class = [rn+'_'+sc for sc in kwargs['stats_to_class']]\n",
    "        levels = kwargs[rn]['levels']\n",
    "        labels = kwargs[rn]['level_labels']\n",
    "        ctag = '_' + kwargs[rn]['class_tag']\n",
    "        for s2c in stats_to_class:\n",
    "            try:\n",
    "                gdf[s2c+ctag] = pd.cut(gdf[s2c], levels, right=True, labels=labels)\n",
    "            except KeyError:\n",
    "                print(\"Key Error exception occurred for raster stat key = {}\".format(s2c))\n",
    "            except Exception as e:\n",
    "                print(\"A non-key error exception occurred: {}\".format(e))\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(gpd.read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n",
      "\n",
      "SQL QUERY = SELECT nuid, ST_TRANSFORM(wkb_geometry, 4326) AS geometry FROM neighborhood_units\n",
      "\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 876 entries, 0 to 875\n",
      "Data columns (total 2 columns):\n",
      "nuid        876 non-null int64\n",
      "geometry    876 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.8+ KB\n",
      "MultiPolygon\n",
      "{'init': 'epsg:4326'}\n"
     ]
    }
   ],
   "source": [
    "# Step 1) Select geometry column either from Postgis db (implemented), or\n",
    "# from shapefile (not yet implemented).  In eithe case, make sure geometry\n",
    "# has a valid epsg Spatial reference assigned to it, such as 4326 (lon/lat)\n",
    "# For a Postgis-derived geometry, this is done on the db-side using ST_TRANSFORM\n",
    "# Note a copy of the original geopandas dataframe is made to preserve the dataframe\n",
    "# obtained from postgis for debugging :-)\n",
    "gdf = get_geodf_geometry(**params['geometry'])\n",
    "gdf_merge = gdf.copy()\n",
    "type(gdf_merge)\n",
    "#gdf.info()\n",
    "gdf_merge.info()\n",
    "print(gdf['geometry'][0].type)\n",
    "print(gdf['geometry'].crs)\n",
    "\n",
    "#gdf = get_geometry_from_file(\"./Data/DisasterNeighborhoods/RLIS_ST_clips_pdx_final.dbf\")\n",
    "#gdf_shape = gpd.read_file(\"./Data/DisasterNeighborhoods/RLIS_ST_clips_pdx_final.dbf\")\n",
    "#gdf_shape.info()\n",
    "#print(gdf_shape['geometry'][0].type)\n",
    "#print(gdf_shape['geometry'].crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for raster file = ./CSZ_M9p0_pgv_site.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/main.py:145: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  with Raster(raster, affine, nodata, band) as rast:\n",
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/io.py:242: FutureWarning: GDAL-style transforms are deprecated and will not be supported in Rasterio 1.0.\n",
      "  self.affine = guard_transform(self.src.transform)\n",
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/main.py:165: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  np.issubdtype(fsrc.array.dtype, float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for raster file = ./CSZ_M9p0_PGD_landslide_dry.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/io.py:294: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for raster file = ./CSZ_M9p0_PGD_landslide_wet.tif\n",
      "Computing statistics for raster file = ./CSZ_M9p0_PGD_liquefaction_wet.tif\n"
     ]
    }
   ],
   "source": [
    "# Steps 2 through 5 are repeated for each raster file\n",
    "# the results for each raster are appended to gdf_merge\n",
    "for raster_name in params['raster']['names']:\n",
    "    # Step 2) Print info about tif file (optional) and get its spatial reference info\n",
    "    raster_file = params['raster']['root'] + raster_name + params['raster']['ext']\n",
    "    print(\"Computing statistics for raster file = {}\".format(raster_file))\n",
    "    srs_raster = get_raster_info_srs(raster_file, print_info=False)\n",
    "\n",
    "    # Step 3) Generate a list of polygons transformed from the srs used in the \n",
    "    # input geodataframe, gdf, to the srs used in the raster file, srs_raster\n",
    "    geom_ras = transform_polygons_from_srsinp_to_srsout(gdf_merge['geometry'], srs_raster)\n",
    "    #print(\"# of rows in transformed geometry ({}) and geodataframe ({}) should be equal!\".format(\n",
    "    #        len(geom_ras), len(gdf)\n",
    "    #))\n",
    "\n",
    "    # Step 4) Use rasterstats to compute analytics on pixel values within specified geometry, \n",
    "    # MUST be polygon or multipolygon and transformed to srs_raster!\n",
    "    # Add stats from pixel values into geodataframe that defines geometry\n",
    "    df_gs = get_raster_stats_df(geom_ras, gdf_merge.index, raster_file, raster_name, \n",
    "                                **params['zonal_stats']\n",
    "    )\n",
    "    \n",
    "    # Step 5) Aggregate the statistics from each raster into a final merged geodataframe\n",
    "    gdf_merge = gdf_merge.join(df_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 876 entries, 0 to 875\n",
      "Data columns (total 22 columns):\n",
      "nuid                          876 non-null int64\n",
      "geometry                      876 non-null object\n",
      "pgv_site_count                876 non-null int64\n",
      "pgv_site_max                  876 non-null float64\n",
      "pgv_site_mean                 876 non-null float64\n",
      "pgv_site_min                  876 non-null float64\n",
      "pgv_site_std                  876 non-null float64\n",
      "PGD_landslide_dry_count       876 non-null int64\n",
      "PGD_landslide_dry_max         876 non-null float64\n",
      "PGD_landslide_dry_mean        876 non-null float64\n",
      "PGD_landslide_dry_min         876 non-null float64\n",
      "PGD_landslide_dry_std         876 non-null float64\n",
      "PGD_landslide_wet_count       876 non-null int64\n",
      "PGD_landslide_wet_max         876 non-null float64\n",
      "PGD_landslide_wet_mean        876 non-null float64\n",
      "PGD_landslide_wet_min         876 non-null float64\n",
      "PGD_landslide_wet_std         876 non-null float64\n",
      "PGD_liquefaction_wet_count    876 non-null int64\n",
      "PGD_liquefaction_wet_max      876 non-null float64\n",
      "PGD_liquefaction_wet_mean     876 non-null float64\n",
      "PGD_liquefaction_wet_min      876 non-null float64\n",
      "PGD_liquefaction_wet_std      876 non-null float64\n",
      "dtypes: float64(16), int64(5), object(1)\n",
      "memory usage: 150.6+ KB\n"
     ]
    }
   ],
   "source": [
    "gdf_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        377267\n",
       "1         88985\n",
       "2         45771\n",
       "3        100965\n",
       "4         84952\n",
       "5        265919\n",
       "6         58271\n",
       "7        232278\n",
       "8         87795\n",
       "9        148959\n",
       "10       108957\n",
       "11       223566\n",
       "12        70334\n",
       "13       178780\n",
       "14        86287\n",
       "15       135061\n",
       "16        51401\n",
       "17        73600\n",
       "18        73584\n",
       "19        93061\n",
       "20       164400\n",
       "21       197726\n",
       "22       133790\n",
       "23       240737\n",
       "24       240284\n",
       "25        82678\n",
       "26       161960\n",
       "27       344087\n",
       "28       849745\n",
       "29        73597\n",
       "         ...   \n",
       "846       43648\n",
       "847      654120\n",
       "848    10377117\n",
       "849     6967467\n",
       "850      133294\n",
       "851     3926059\n",
       "852     4429579\n",
       "853     4364742\n",
       "854     3463126\n",
       "855      470926\n",
       "856      767578\n",
       "857      570767\n",
       "858      888366\n",
       "859      676081\n",
       "860      736631\n",
       "861       80482\n",
       "862      133026\n",
       "863      183521\n",
       "864      756460\n",
       "865       69392\n",
       "866      103615\n",
       "867      721074\n",
       "868     6712776\n",
       "869     4807869\n",
       "870    16218453\n",
       "871    22465672\n",
       "872     5101747\n",
       "873     4030346\n",
       "874    16421683\n",
       "875    21955550\n",
       "Name: PGD_landslide_dry_count, Length: 876, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_merge['PGD_landslide_dry_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 876 entries, 0 to 875\n",
      "Data columns (total 34 columns):\n",
      "nuid                            876 non-null int64\n",
      "geometry                        876 non-null object\n",
      "pgv_site_count                  876 non-null int64\n",
      "pgv_site_max                    876 non-null float64\n",
      "pgv_site_mean                   876 non-null float64\n",
      "pgv_site_min                    876 non-null float64\n",
      "pgv_site_std                    876 non-null float64\n",
      "PGD_landslide_dry_count         876 non-null int64\n",
      "PGD_landslide_dry_max           876 non-null float64\n",
      "PGD_landslide_dry_mean          876 non-null float64\n",
      "PGD_landslide_dry_min           876 non-null float64\n",
      "PGD_landslide_dry_std           876 non-null float64\n",
      "PGD_landslide_wet_count         876 non-null int64\n",
      "PGD_landslide_wet_max           876 non-null float64\n",
      "PGD_landslide_wet_mean          876 non-null float64\n",
      "PGD_landslide_wet_min           876 non-null float64\n",
      "PGD_landslide_wet_std           876 non-null float64\n",
      "PGD_liquefaction_wet_count      876 non-null int64\n",
      "PGD_liquefaction_wet_max        876 non-null float64\n",
      "PGD_liquefaction_wet_mean       876 non-null float64\n",
      "PGD_liquefaction_wet_min        876 non-null float64\n",
      "PGD_liquefaction_wet_std        876 non-null float64\n",
      "pgv_site_min_MMI                876 non-null category\n",
      "pgv_site_max_MMI                876 non-null category\n",
      "pgv_site_mean_MMI               876 non-null category\n",
      "PGD_landslide_dry_min_DI        876 non-null category\n",
      "PGD_landslide_dry_max_DI        876 non-null category\n",
      "PGD_landslide_dry_mean_DI       876 non-null category\n",
      "PGD_landslide_wet_min_DI        876 non-null category\n",
      "PGD_landslide_wet_max_DI        873 non-null category\n",
      "PGD_landslide_wet_mean_DI       876 non-null category\n",
      "PGD_liquefaction_wet_min_DI     876 non-null category\n",
      "PGD_liquefaction_wet_max_DI     873 non-null category\n",
      "PGD_liquefaction_wet_mean_DI    876 non-null category\n",
      "dtypes: category(12), float64(16), int64(5), object(1)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 6) Classify a subset of the geometry statistics, converting the calculated\n",
    "# stat in pixel values to a label describing the stats intensity bin\n",
    "if 'stats_classification' in params:\n",
    "    gdf_merge_class = get_stats_classification(gdf_merge, **params['stats_classification'])\n",
    "gdf_merge_class.info()\n",
    "#print(gdf_merge_class[['PGD_landslide_dry_max', 'PGD_landslide_dry_max_DI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7) Option to write results to csv file\n",
    "if 'write_csv' in params:\n",
    "    gdf_merge_class.to_csv(params['write_csv']['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-122.62246806545195, 45.461206507654005), (-122.62246806545195, 45.45580794713887), (-122.63013918411258, 45.45580794713887), (-122.63013918411258, 45.461206507654005), (-122.62246806545195, 45.461206507654005)]\n",
      "The returned azimuth, -180.0, should point N-S (i.e. 0 or 180)\n",
      "The returned distance, 599.9999990960112, should be equal to 2*xy_offset, 600, within roundoff.\n"
     ]
    }
   ],
   "source": [
    "#If geometry was build from point, then check the length of square to make\n",
    "# sure it matches the input length, xy_offset\n",
    "if 'from_point' in params['geometry']:\n",
    "    poly_coords = list(gdf_merge_class['geometry'][0].exterior.coords)\n",
    "    print(poly_coords)\n",
    "    g = Geod(ellps='WGS84')\n",
    "    az12,az21,dist = g.inv(poly_coords[0][0], poly_coords[0][1], poly_coords[1][0], poly_coords[1][1])\n",
    "    print(\"The returned azimuth, {}, should point N-S (i.e. 0 or 180)\".format(az12))\n",
    "    print(\"The returned distance, {}, should be equal to 2*xy_offset, {}, within roundoff.\"\n",
    "          .format(dist, 2*params['geometry']['from_point']['xy_offset']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f67b006ba20>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAF2CAYAAACGZ1rqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABhJJREFUeJzt3LENwzAQBEHTcDnsvxL182rBgQUC65mYwWWLT7hm5gUANL1PDwAAniP0ABAm9AAQJvQAECb0ABAm9AAQJvQAECb0ABAm9AAQJvQAEPY5PeAXruvyjy8Af2Pvvb5966IHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgDChB4AwoQeAMKEHgLA1M6c3AAAPcdEDQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANAmNADQJjQA0CY0ANA2A2hzAznE40pjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For geometry input from point, this plot should be a rectangle, not\n",
    "# necessarily a square do to map projection...\n",
    "gplt.polyplot(gdf_merge_class.geometry,\n",
    "                   facecolor='lightgray', edgecolor='gray', linewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/pysal/esda/mapclassify.py:902: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cuts = np.arange(min_y + width, max_y + width, width)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arange: cannot compute length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-f627f758b758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mscheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'equal_interval'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol2plot_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/geoplot/geoplot.py\u001b[0m in \u001b[0;36mchoropleth\u001b[0;34m(df, projection, hue, scheme, k, cmap, categorical, vmin, vmax, legend, legend_kwargs, legend_labels, extent, figsize, ax, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_discrete_colorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhue_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/geoplot/geoplot.py\u001b[0m in \u001b[0;36m_discrete_colorize\u001b[0;34m(categorical, hue, scheme, k, cmap, vmin, vmax)\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \"\"\"\n\u001b[1;32m   2481\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m         \u001b[0mbinning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__pysal_choro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mbinedges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbinning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbinning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/geopandas/plotting.py\u001b[0m in \u001b[0;36m__pysal_choro\u001b[0;34m(values, scheme, k)\u001b[0m\n\u001b[1;32m    513\u001b[0m             raise ValueError(\"Invalid scheme. Scheme must be in the\"\n\u001b[1;32m    514\u001b[0m                              \" set: %r\" % schemes.keys())\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mbinning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschemes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/pysal/esda/mapclassify.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, k)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mMap_Classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Equal Interval'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/pysal/esda/mapclassify.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Map Classifier'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/pysal/esda/mapclassify.py\u001b[0m in \u001b[0;36m_classify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_bins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbin1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.6/site-packages/pysal/esda/mapclassify.py\u001b[0m in \u001b[0;36m_set_bins\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0mcuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# handle overshooting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mcuts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arange: cannot compute length"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a map showing distribution of df column, col2plot_y\n",
    "#col2plot_y = 'casualties_avetotal'\n",
    "#col2plot_y = 'buildingloss'\n",
    "#col2plot_y = 'buildingloss_ratio'\n",
    "col2plot_y = 'pgv_site_max'\n",
    "\n",
    "gplt.choropleth(gdf_merge,\n",
    "                hue=gdf_merge[col2plot_y],  # Display data, passed as a Series\n",
    "                projection=gplt.crs.AlbersEqualArea(),\n",
    "                cmap='Purples',\n",
    "                linewidth=0.5,\n",
    "                edgecolor='black',\n",
    "                k=5,\n",
    "                legend=True,\n",
    "                scheme='equal_interval',\n",
    "                figsize=(12, 12)\n",
    ")\n",
    "plt.title(\"{}\".format(col2plot_y), fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
