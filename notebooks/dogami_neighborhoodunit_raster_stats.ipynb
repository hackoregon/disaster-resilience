{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook for analyzing DOGAMI data, see Scott Tse's emergence-response notebook at\n",
    "# https://github.com/hackoregon/emergency-response/blob/analytics/notebooks/census_eda_geo.ipynb\n",
    "# NOTE: Don't need all of these!\n",
    "# Import modules included in \"kitchen-sink\"\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "import sys\n",
    "# Import modules NOT included in \"kitchen-sink\", not sure about osgeo...\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import geoplot as gplt\n",
    "from osgeo import osr, ogr \n",
    "#import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.D. Pearce, 04/16/18\n",
    "\n",
    "Notebook for computing statistics on raster pixel values contained within a geometry (shape) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ALL parameters in dictionary (convert to json config file!)\n",
    "params = {\n",
    "    'raster': {\n",
    "        'root': './CSZ_M9p0_',\n",
    "        #'names': ['pgv_site', 'PGD_landslide_dry'],\n",
    "        'names': ['PGD_landslide_wet', 'PGD_liquefaction_wet'],\n",
    "        'ext': '.tif'\n",
    "    },\n",
    "    'geometry': {\n",
    "        'from_postgis': {\n",
    "            'query': {\n",
    "                'table_name': 'neighborhood_units',\n",
    "                'geometry_column': 'wkb_geometry',\n",
    "                'epsg_code': 4326\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'zonal_stats': {\n",
    "        'layer': 1,\n",
    "        'stats': ['count', 'min', 'max', 'mean', 'std']\n",
    "        \n",
    "    },\n",
    "    'stats_classification': {\n",
    "        'stats_to_class': ['min', 'max', 'mean'],\n",
    "        'pgv_site': {\n",
    "            'levels': [-9999, 0.1, 1.1, 3.4, 8.1, 16, 31, 60, 116, 9999],\n",
    "            'level_labels': ['I', 'II-III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X'],\n",
    "            'class_name': 'Modified Mercalli Intensity',\n",
    "            'class_tag': 'MMI'\n",
    "        },\n",
    "        'PGD_landslide_dry': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Landslide Intensity (Dry)',\n",
    "          'class_tag': 'DI'\n",
    "        },\n",
    "        'PGD_landslide_wet': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Landslide Intensity (Wet)',\n",
    "          'class_tag': 'DI'\n",
    "        },\n",
    "        'PGD_liquefaction_wet': {\n",
    "          'levels': [-9999, 0, 10, 30, 100, 9999],\n",
    "          'level_labels': ['None', 'Low', 'Moderate', 'High', 'Very High'],\n",
    "          'class_name': 'Liquefaction Intensity (Wet)',\n",
    "          'class_tag': 'DI'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for interacting with PostGres database\n",
    "def pgconnect():\n",
    "    \"\"\"Establish connection to PostGres database using the parameters specified in .env file.\n",
    "    First, walk root diretory to find and load .env file w/ PostGres variables defining database, \n",
    "    user, host, password, and port variables.\n",
    "    Then, return connection to database from psycopg2.connect\n",
    "    \"\"\"\n",
    "    try:\n",
    "        load_dotenv(find_dotenv())\n",
    "        conn = psycopg2.connect(database=os.environ.get(\"PG_DATABASE\"), user=os.environ.get(\"PG_USER\"), \n",
    "                            password = os.environ.get(\"PG_PASSWORD\"), \n",
    "                            host=os.environ.get(\"PG_HOST\"), port=os.environ.get(\"PG_PORT\"))\n",
    "        print(\"Opened database successfully\\n\")\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"I am unable to connect to the database\\n\")\n",
    "        print(e)\n",
    "        print(e.pgcode)\n",
    "        print(e.pgerror)\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "def get_query_string(table_name, geometry_column, epsg_code):\n",
    "    '''Build query string from parameter inputs defining table name, geometry column\n",
    "    name, and epsg code.\n",
    "    '''\n",
    "    query_string = 'SELECT ST_TRANSFORM({}, {}) AS geometry FROM {}'.format(\n",
    "            geometry_column, epsg_code, table_name\n",
    "    )\n",
    "    return query_string\n",
    "    \n",
    "def get_geometry_from_postgis(postgis_params):\n",
    "    '''\n",
    "    This function takes a dictionary containing parameters for building a SQL query,\n",
    "    as defined in get_query_string, then connects to a postgis db, selects the \n",
    "    data specified in the query, and finally returns a geodataframe with a single\n",
    "    column named geometry that contains shape data.\n",
    "    '''\n",
    "    query_string = get_query_string(**postgis_params['query'])\n",
    "    conn = pgconnect()\n",
    "    #cur = conn.cursor()\n",
    "    print(\"SQL QUERY = \"+query_string+'\\r\\n')\n",
    "    try:\n",
    "        geo_df = gpd.GeoDataFrame.from_postgis(\n",
    "            query_string, \n",
    "            conn, \n",
    "            geom_col='geometry', \n",
    "            crs={'init': u'epsg:{}'.format(postgis_params['query']['epsg_code'])}, \n",
    "            coerce_float=False\n",
    "        )\n",
    "        return geo_df\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for manipulating geoshapes and raster files\n",
    "def get_gdfcrs_epsg(gdf):\n",
    "    \"\"\"Return integer EPSG code corresponding to Coordinate Reference\n",
    "    used in input geodataframe, gdf. Attribute gdf.crs must contain\n",
    "    a dict with key = 'init' that contains a string starting with 'epsg',\n",
    "    followed by a colon, followed by an integer as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dfepsg = gdf.crs['init'].split(':')\n",
    "        if dfepsg[0] == 'epsg':\n",
    "            return int(dfepsg[1])\n",
    "    except:\n",
    "        print('Error: geodataframe crs = {}, unrecognized EPSG integer'.format(gdf.crs['init']))\n",
    "\n",
    "def get_raster_info_srs(raster_file, print_info=True):\n",
    "    \"\"\"Print information about raster file, and return its\n",
    "    spatial reference system using gdal.\n",
    "    \"\"\"\n",
    "    if print_info:\n",
    "        try:\n",
    "            print(gdal.Info(raster_file))\n",
    "        except:\n",
    "            print(\"Error reading info from raster file = {}\".format(raster_file))\n",
    "    try:\n",
    "        raster = gdal.Open(raster_file)\n",
    "    except:\n",
    "        print(\"Error opening raster file = {}\".format(raster_file))\n",
    "    else:\n",
    "        raster_srs = osr.SpatialReference()\n",
    "        raster_srs.ImportFromWkt(raster.GetProjection())\n",
    "        return raster_srs\n",
    "    \n",
    "def transform_polygons_from_srsinp_to_srsout(geom_col, srs_out):\n",
    "    \"\"\"Transform list of georeferenced polygon geometries from geopandas\n",
    "    dataframe geometry column, geom_col, to the desired output Spatial Reference, srs_out.\n",
    "    The input geometry column, geom_col, MUST have a valid epsg code defining its Spatial \n",
    "    Reference (SRS).\"\"\"\n",
    "    # Define input spatial reference using epsg code from gdf\n",
    "    srs_inp = ogr.osr.SpatialReference()\n",
    "    srs_inp.ImportFromEPSG(get_gdfcrs_epsg(geom_col))\n",
    "    poly_out = []\n",
    "    # Define list of polygons in transformed spatial reference\n",
    "    for g in geom_col:\n",
    "        # If MultiPolygon, then assume it contains only one Polygon\n",
    "        if g.type == 'MultiPolygon':\n",
    "            poly = ogr.CreateGeometryFromWkt(g.geoms[0].wkt)\n",
    "        elif g.type == 'Polygon':\n",
    "            # Need to test this\n",
    "            poly = ogr.CreateGeometryFromWkt(g.geoms.wkt)\n",
    "        else:\n",
    "            print(\"Error: geometry = {}, MUST be Polygon or MultiPolygon\".format(g.type))\n",
    "        poly.AssignSpatialReference(srs_inp)\n",
    "        # Transform point co-ordinates so that they are in same projection as raster \n",
    "        poly.Transform(osr.CoordinateTransformation(srs_inp, srs_out))\n",
    "        poly_out.append(poly.ExportToWkt())\n",
    "    return poly_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for computing raster statistics\n",
    "def get_raster_stats_df(geom_ras, df_index, raster_file, raster_name, **kwargs):\n",
    "    \"\"\"Compute raster statistics for input geometry and raster file.\n",
    "    Return results in dataframe\n",
    "    \"\"\"\n",
    "    geomstats = zonal_stats(geom_ras, raster_file, **kwargs)\n",
    "    df_gs = pd.DataFrame(geomstats, index=df_index)\n",
    "    df_gs.rename(columns={co: raster_name+'_'+co for co in df_gs.columns}, inplace=True)\n",
    "    return df_gs\n",
    "\n",
    "# Functions for classifying raster statistics\n",
    "def get_stats_classification(gdf, **kwargs):\n",
    "    \"\"\"Classify raster statistics using specified parameters in kwargs\"\"\"\n",
    "    raster_names = [rn for rn in kwargs.keys() if rn != \"stats_to_class\"]\n",
    "    for rn in raster_names:\n",
    "        stats_to_class = [rn+'_'+sc for sc in kwargs['stats_to_class']]\n",
    "        levels = kwargs[rn]['levels']\n",
    "        labels = kwargs[rn]['level_labels']\n",
    "        ctag = '_' + kwargs[rn]['class_tag']\n",
    "        for s2c in stats_to_class:\n",
    "            try:\n",
    "                gdf[s2c+ctag] = pd.cut(gdf[s2c], levels, right=True, labels=labels)\n",
    "            except KeyError:\n",
    "                print(\"Key Error exception occurred for raster stat key = {}\".format(s2c))\n",
    "            except Exception as e:\n",
    "                print(\"A non-key error exception occurred: {}\".format(e))\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n",
      "\n",
      "SQL QUERY = SELECT ST_TRANSFORM(wkb_geometry, 4326) AS geometry FROM neighborhood_units\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1) Select geometry column either from Postgis db (implemented), or\n",
    "# from shapefile (not yet implemented).  In eithe case, make sure geometry\n",
    "# has a valid epsg Spatial reference assigned to it, such as 4326 (lon/lat)\n",
    "# For a Postgis-derived geometry, this is done on the db-side using ST_TRANSFORM\n",
    "# Note a copy of the original geopandas dataframe is made to preserve the dataframe\n",
    "# obtained from postgis for debugging :-)\n",
    "gdf = get_geometry_from_postgis(params['geometry']['from_postgis'])\n",
    "gdf_merge = gdf.copy()\n",
    "#gdf.info()\n",
    "#gdf_merge.info()\n",
    "#print(gdf['geometry'][0].type)\n",
    "#print(gdf['geometry'].crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for raster file = ./CSZ_M9p0_PGD_landslide_wet.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/main.py:145: FutureWarning: The value of this property will change in version 1.0. Please see https://github.com/mapbox/rasterio/issues/86 for details.\n",
      "  with Raster(raster, affine, nodata, band) as rast:\n",
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/io.py:242: FutureWarning: GDAL-style transforms are deprecated and will not be supported in Rasterio 1.0.\n",
      "  self.affine = guard_transform(self.src.transform)\n",
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/io.py:294: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n",
      "/home/jupyter/.conda/envs/jupyter/lib/python3.6/site-packages/rasterstats/main.py:165: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  np.issubdtype(fsrc.array.dtype, float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for raster file = ./CSZ_M9p0_PGD_liquefaction_wet.tif\n"
     ]
    }
   ],
   "source": [
    "# Steps 2 through 5 are repeated for each raster file\n",
    "# the results for each raster are appended to gdf_merge\n",
    "for raster_name in params['raster']['names']:\n",
    "    # Step 2) Print info about tif file (optional) and get its spatial reference info\n",
    "    raster_file = params['raster']['root'] + raster_name + params['raster']['ext']\n",
    "    print(\"Computing statistics for raster file = {}\".format(raster_file))\n",
    "    srs_raster = get_raster_info_srs(raster_file, print_info=False)\n",
    "\n",
    "    # Step 3) Generate a list of polygons transformed from the srs used in the \n",
    "    # input geodataframe, gdf, to the srs used in the raster file, srs_raster\n",
    "    geom_ras = transform_polygons_from_srsinp_to_srsout(gdf_merge['geometry'], srs_raster)\n",
    "    #print(\"# of rows in transformed geometry ({}) and geodataframe ({}) should be equal!\".format(\n",
    "    #        len(geom_ras), len(gdf)\n",
    "    #))\n",
    "\n",
    "    # Step 4) Use rasterstats to compute analytics on pixel values within specified geometry, \n",
    "    # MUST be polygon or multipolygon and transformed to srs_raster!\n",
    "    # Add stats from pixel values into geodataframe that defines geometry\n",
    "    df_gs = get_raster_stats_df(geom_ras, gdf_merge.index, raster_file, raster_name, \n",
    "                                **params['zonal_stats']\n",
    "    )\n",
    "    \n",
    "    # Step 5) Aggregate the statistics from each raster into a final merged geodataframe\n",
    "    gdf_merge = gdf_merge.join(df_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 876 entries, 0 to 875\n",
      "Data columns (total 21 columns):\n",
      "geometry                      876 non-null object\n",
      "pgv_site_count                876 non-null int64\n",
      "pgv_site_max                  876 non-null float64\n",
      "pgv_site_mean                 876 non-null float64\n",
      "pgv_site_min                  876 non-null float64\n",
      "pgv_site_std                  876 non-null float64\n",
      "PGD_landslide_dry_count       876 non-null int64\n",
      "PGD_landslide_dry_max         876 non-null float64\n",
      "PGD_landslide_dry_mean        876 non-null float64\n",
      "PGD_landslide_dry_min         876 non-null float64\n",
      "PGD_landslide_dry_std         876 non-null float64\n",
      "PGD_landslide_wet_count       876 non-null int64\n",
      "PGD_landslide_wet_max         876 non-null float64\n",
      "PGD_landslide_wet_mean        876 non-null float64\n",
      "PGD_landslide_wet_min         876 non-null float64\n",
      "PGD_landslide_wet_std         876 non-null float64\n",
      "PGD_liquefaction_wet_count    876 non-null int64\n",
      "PGD_liquefaction_wet_max      876 non-null float64\n",
      "PGD_liquefaction_wet_mean     876 non-null float64\n",
      "PGD_liquefaction_wet_min      876 non-null float64\n",
      "PGD_liquefaction_wet_std      876 non-null float64\n",
      "dtypes: float64(16), int64(4), object(1)\n",
      "memory usage: 143.8+ KB\n"
     ]
    }
   ],
   "source": [
    "gdf_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6) Classify a subset of the geometry statistics, converting the calculated\n",
    "# stat in pixel values to a label describing the stats intensity bin\n",
    "if 'stats_classification' in params:\n",
    "    gdf_merge_class = get_stats_classification(gdf_merge, **params['stats_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 876 entries, 0 to 875\n",
      "Data columns (total 33 columns):\n",
      "geometry                        876 non-null object\n",
      "pgv_site_count                  876 non-null int64\n",
      "pgv_site_max                    876 non-null float64\n",
      "pgv_site_mean                   876 non-null float64\n",
      "pgv_site_min                    876 non-null float64\n",
      "pgv_site_std                    876 non-null float64\n",
      "PGD_landslide_dry_count         876 non-null int64\n",
      "PGD_landslide_dry_max           876 non-null float64\n",
      "PGD_landslide_dry_mean          876 non-null float64\n",
      "PGD_landslide_dry_min           876 non-null float64\n",
      "PGD_landslide_dry_std           876 non-null float64\n",
      "PGD_landslide_wet_count         876 non-null int64\n",
      "PGD_landslide_wet_max           876 non-null float64\n",
      "PGD_landslide_wet_mean          876 non-null float64\n",
      "PGD_landslide_wet_min           876 non-null float64\n",
      "PGD_landslide_wet_std           876 non-null float64\n",
      "PGD_liquefaction_wet_count      876 non-null int64\n",
      "PGD_liquefaction_wet_max        876 non-null float64\n",
      "PGD_liquefaction_wet_mean       876 non-null float64\n",
      "PGD_liquefaction_wet_min        876 non-null float64\n",
      "PGD_liquefaction_wet_std        876 non-null float64\n",
      "pgv_site_min_MMI                876 non-null category\n",
      "pgv_site_max_MMI                876 non-null category\n",
      "pgv_site_mean_MMI               876 non-null category\n",
      "PGD_landslide_dry_min_DI        876 non-null category\n",
      "PGD_landslide_dry_max_DI        876 non-null category\n",
      "PGD_landslide_dry_mean_DI       876 non-null category\n",
      "PGD_landslide_wet_min_DI        876 non-null category\n",
      "PGD_landslide_wet_max_DI        873 non-null category\n",
      "PGD_landslide_wet_mean_DI       876 non-null category\n",
      "PGD_liquefaction_wet_min_DI     876 non-null category\n",
      "PGD_liquefaction_wet_max_DI     873 non-null category\n",
      "PGD_liquefaction_wet_mean_DI    876 non-null category\n",
      "dtypes: category(12), float64(16), int64(4), object(1)\n",
      "memory usage: 157.0+ KB\n",
      "     PGD_landslide_dry_max PGD_landslide_dry_max_DI\n",
      "0                     81.0                     High\n",
      "1                     81.0                     High\n",
      "2                      0.0                     None\n",
      "3                      0.0                     None\n",
      "4                     81.0                     High\n",
      "5                     81.0                     High\n",
      "6                      0.0                     None\n",
      "7                     81.0                     High\n",
      "8                     81.0                     High\n",
      "9                     81.0                     High\n",
      "10                     0.0                     None\n",
      "11                    81.0                     High\n",
      "12                    81.0                     High\n",
      "13                    81.0                     High\n",
      "14                    58.0                     High\n",
      "15                    81.0                     High\n",
      "16                     0.0                     None\n",
      "17                     0.0                     None\n",
      "18                     0.0                     None\n",
      "19                     0.0                     None\n",
      "20                     7.0                      Low\n",
      "21                    81.0                     High\n",
      "22                    81.0                     High\n",
      "23                    81.0                     High\n",
      "24                    81.0                     High\n",
      "25                     0.0                     None\n",
      "26                    81.0                     High\n",
      "27                    81.0                     High\n",
      "28                    81.0                     High\n",
      "29                    81.0                     High\n",
      "..                     ...                      ...\n",
      "846                    0.0                     None\n",
      "847                  109.0                Very High\n",
      "848                  139.0                Very High\n",
      "849                  139.0                Very High\n",
      "850                  139.0                Very High\n",
      "851                  139.0                Very High\n",
      "852                  139.0                Very High\n",
      "853                  139.0                Very High\n",
      "854                  139.0                Very High\n",
      "855                  139.0                Very High\n",
      "856                  139.0                Very High\n",
      "857                  139.0                Very High\n",
      "858                  139.0                Very High\n",
      "859                  139.0                Very High\n",
      "860                  139.0                Very High\n",
      "861                   20.0                 Moderate\n",
      "862                  139.0                Very High\n",
      "863                   20.0                 Moderate\n",
      "864                  139.0                Very High\n",
      "865                    0.0                     None\n",
      "866                  139.0                Very High\n",
      "867                  139.0                Very High\n",
      "868                  167.0                Very High\n",
      "869                  139.0                Very High\n",
      "870                  167.0                Very High\n",
      "871                  215.0                Very High\n",
      "872                  167.0                Very High\n",
      "873                  167.0                Very High\n",
      "874                  187.0                Very High\n",
      "875                  215.0                Very High\n",
      "\n",
      "[876 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Classify specified raster statistics contained in dataframe column(s)\n",
    "gdf_merge_class.info()\n",
    "print(gdf_merge_class[['PGD_landslide_dry_max', 'PGD_landslide_dry_max_DI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merge_class.to_csv(\"./DOGAMI_neighborhoodunit_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a map showing distribution of df column, col2plot_y\n",
    "#col2plot_y = 'casualties_avetotal'\n",
    "#col2plot_y = 'buildingloss'\n",
    "#col2plot_y = 'buildingloss_ratio'\n",
    "col2plot_y = 'nupv_mean'\n",
    "\n",
    "gplt.choropleth(gdf_merge,\n",
    "                hue=gdf_merge[col2plot_y],  # Display data, passed as a Series\n",
    "                projection=gplt.crs.AlbersEqualArea(),\n",
    "                cmap='Purples',\n",
    "                linewidth=0.5,\n",
    "                edgecolor='black',\n",
    "                k=5,\n",
    "                legend=True,\n",
    "                scheme='equal_interval',\n",
    "                figsize=(12, 12)\n",
    ")\n",
    "plt.title(\"{}\".format(col2plot_y), fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
